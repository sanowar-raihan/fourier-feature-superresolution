{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AudioSuperRes.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoommf5aSVjAPnMYAogcBq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cSeU0HyD5WL"
      },
      "source": [
        "## Install torchaudio\r\n",
        "torchaudio not installed in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw7mCEsKDzY2"
      },
      "source": [
        "!pip install torchaudio==0.7.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkOTapNeEFhB"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rUynMDGEHRj"
      },
      "source": [
        "import math\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchaudio\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchaudio.datasets.utils import download_url\r\n",
        "from IPython import display\r\n",
        "\r\n",
        "torchaudio.set_audio_backend(\"sox_io\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BOhKHO7E-Wn"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XNd2_f6FE5E"
      },
      "source": [
        "class FourierLayer(nn.Module):\r\n",
        "    def __init__(self, in_features, out_features, scale):\r\n",
        "        super().__init__()\r\n",
        "        B = torch.randn(in_features, out_features)*scale\r\n",
        "        self.register_buffer(\"B\", B)\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        x_proj = torch.matmul(2*math.pi*x, self.B)\r\n",
        "        out = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\r\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRWNGHSPF9iF"
      },
      "source": [
        "class SignalRegressor(nn.Module):\r\n",
        "    def __init__(self, in_features, fourier_features,\r\n",
        "                 hidden_features, hidden_layers, out_features, scale):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.net = []\r\n",
        "        if fourier_features is not None:\r\n",
        "            self.net.append(FourierLayer(in_features, fourier_features, scale))\r\n",
        "            self.net.append(nn.Linear(2*fourier_features, hidden_features))\r\n",
        "            self.net.append(nn.ReLU())\r\n",
        "        else:\r\n",
        "            self.net.append(nn.Linear(in_features, hidden_features))\r\n",
        "            self.net.append(nn.ReLU())\r\n",
        "        \r\n",
        "        for i in range(hidden_layers-1):\r\n",
        "            self.net.append(nn.Linear(hidden_features, hidden_features))\r\n",
        "            self.net.append(nn.ReLU())\r\n",
        "\r\n",
        "        self.net.append(nn.Linear(hidden_features, out_features))\r\n",
        "        self.net.append(nn.Tanh())\r\n",
        "        self.net = nn.Sequential(*self.net)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.net(x)\r\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GEYHfmHIu8V"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJB1WKpWIwcW"
      },
      "source": [
        "class AudioDataset(Dataset):\r\n",
        "    def __init__(self, audio_path):\r\n",
        "        super().__init__()\r\n",
        "        self.audio_path = audio_path\r\n",
        "        self.metadata = torchaudio.info(audio_path)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        frames, rate = torchaudio.load(self.audio_path, channels_first=False)\r\n",
        "        times = torch.linspace(0, 1, steps=frames.shape[0])\r\n",
        "\r\n",
        "        return times, frames\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP_cj9AjW2Cj"
      },
      "source": [
        "## Play Audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUbnaFk1W5eP"
      },
      "source": [
        "web_url = \"https://upload.wikimedia.org/wikipedia/commons/7/70/Emotional_piano.wav\"\r\n",
        "download_url(web_url, \".\", \"piano.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnpnf8zHXKuQ"
      },
      "source": [
        "audio_path = \"piano.wav\"\r\n",
        "display.Audio(audio_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9MjVEDnXoB8"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMbJJzYAXZho"
      },
      "source": [
        "audio_data = AudioDataset(audio_path)\r\n",
        "audio_loader = DataLoader(audio_data, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO15pwWciUx_"
      },
      "source": [
        "## Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piGGV21ViRu0"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "total_steps = 2000\r\n",
        "summary_interval = 100\r\n",
        "\r\n",
        "times, frames = next(iter(audio_loader))\r\n",
        "times, frames = times.squeeze().to(device), frames.squeeze().to(device)\r\n",
        "train_coords, train_values = times[::2].reshape(-1, 1), frames[::2]   # use every other frame for training\r\n",
        "test_coords, test_values = times.reshape(-1, 1), frames    # use all the frames for evaluation\r\n",
        "\r\n",
        "audio_regressor = SignalRegressor(in_features=1, fourier_features=256,\r\n",
        "                                  hidden_features=256, hidden_layers=4,\r\n",
        "                                  out_features=audio_data.metadata.num_channels,\r\n",
        "                                  scale=5000).to(device)\r\n",
        "optim = torch.optim.Adam(lr=1e-4, params=audio_regressor.parameters())\r\n",
        "\r\n",
        "for step in range(1, total_steps+1):\r\n",
        "    audio_regressor.train()\r\n",
        "    optim.zero_grad()\r\n",
        "    output = audio_regressor(train_coords)\r\n",
        "    train_loss = F.mse_loss(output, train_values)\r\n",
        "    train_loss.backward()\r\n",
        "    optim.step()\r\n",
        "\r\n",
        "    if not step % summary_interval:\r\n",
        "        audio_regressor.eval()\r\n",
        "        with torch.no_grad():\r\n",
        "            prediction = audio_regressor(test_coords)\r\n",
        "            test_loss = F.mse_loss(prediction, test_values)\r\n",
        "            test_psnr = -10*torch.log10(test_loss)\r\n",
        "            print(f\"Step: {step}, Test PSNR: {test_psnr.item():.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKM-NcHc1hlz"
      },
      "source": [
        "## Temporal SuperResolution result\r\n",
        "increase audio frame rate by 2x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v_0WkwP1hJw"
      },
      "source": [
        "super_path = \"piano_super.wav\"\r\n",
        "torchaudio.save(super_path, src=prediction.cpu(),\r\n",
        "                sample_rate=audio_data.metadata.sample_rate,\r\n",
        "                channels_first=False)\r\n",
        "\r\n",
        "display.Audio(super_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}